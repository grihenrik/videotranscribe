# YouTube Transcription Tool

A modern, full-stack web application that transcribes YouTube videos using either YouTube's available captions or OpenAI's Whisper speech-to-text model. Built with FastAPI and featuring real-time progress updates.

## âœ¨ Features

- **ğŸ¥ Single Video Transcription** - Process individual YouTube videos
- **ğŸ“š Batch Processing** - Transcribe multiple videos at once  
- **ğŸµ Playlist Support** - Process entire YouTube playlists
- **ğŸ“ Multiple Output Formats** - Download transcriptions as TXT, SRT, or VTT files
- **âš¡ Real-time Progress** - Live updates via WebSocket connections
- **ğŸ”„ Smart Mode Selection** - Auto-detect best transcription method
- **ğŸŒ Modern Web Interface** - Clean, responsive design with Bootstrap

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- FFmpeg (for audio processing)
- OpenAI API key (optional, for Whisper transcription)

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd youtube-transcription-tool
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up environment variables** (optional)
   ```bash
   export OPENAI_API_KEY="your-openai-api-key"
   ```

4. **Start the application**
   ```bash
   python main.py
   ```

5. **Access the web interface**
   Open your browser to `http://localhost:5000`

## ğŸ› ï¸ Usage

### Single Video Transcription
1. Navigate to the **Single Video** tab
2. Enter a YouTube URL
3. Select transcription mode:
   - **Auto** - Try captions first, fallback to Whisper
   - **Captions** - YouTube captions only
   - **Whisper** - AI speech recognition only
4. Choose target language
5. Click **Transcribe Video**

### Batch Processing
1. Go to the **Batch Processing** tab
2. Enter multiple YouTube URLs (one per line)
3. Configure processing settings
4. Click **Process Batch**

### Playlist Processing
1. Switch to the **Playlist** tab
2. Enter a YouTube playlist URL
3. Set your preferences
4. Click **Process Playlist**

## ğŸ“ Project Structure

```
â”œâ”€â”€ app/                    # FastAPI application
â”‚   â”œâ”€â”€ api/               # API routes and endpoints
â”‚   â”‚   â”œâ”€â”€ transcribe.py  # Transcription endpoints
â”‚   â”‚   â”œâ”€â”€ download.py    # File download endpoints
â”‚   â”‚   â””â”€â”€ progress_ws.py # WebSocket progress updates
â”‚   â”œâ”€â”€ core/              # Core configuration
â”‚   â”‚   â”œâ”€â”€ config.py      # Application settings
â”‚   â”‚   â””â”€â”€ logging.py     # Logging configuration
â”‚   â”œâ”€â”€ models/            # Pydantic data models
â”‚   â”‚   â”œâ”€â”€ request.py     # Request models
â”‚   â”‚   â””â”€â”€ response.py    # Response models
â”‚   â”œâ”€â”€ services/          # Business logic services
â”‚   â”‚   â”œâ”€â”€ youtube_service.py    # YouTube API interactions
â”‚   â”‚   â”œâ”€â”€ whisper_service.py    # Whisper transcription
â”‚   â”‚   â””â”€â”€ cache_service.py      # Caching layer
â”‚   â””â”€â”€ utils/             # Utility functions
â”‚       â”œâ”€â”€ file_manager.py       # File operations
â”‚       â”œâ”€â”€ xml_parser.py         # Caption parsing
â”‚       â””â”€â”€ youtube.py            # YouTube helpers
â”œâ”€â”€ static/                # Frontend assets
â”‚   â”œâ”€â”€ css/              # Stylesheets
â”‚   â”œâ”€â”€ js/               # JavaScript files
â”‚   â””â”€â”€ index.html        # Main web interface
â”œâ”€â”€ tests/                 # Test files
â”œâ”€â”€ main.py               # Application entry point
â””â”€â”€ README.md             # This file
```

## âš™ï¸ Configuration

The application can be configured through environment variables:

| Variable | Description | Default |
|----------|-------------|---------|
| `OPENAI_API_KEY` | OpenAI API key for Whisper | None |
| `WHISPER_MODEL` | Whisper model size (tiny, base, small, medium, large) | base |
| `CACHE_TTL` | Cache time-to-live in seconds | 3600 |
| `LOG_LEVEL` | Logging level | INFO |

## ğŸ”§ API Reference

### Core Endpoints

- `POST /api/transcribe` - Submit transcription job
- `GET /api/job/{job_id}/status` - Check job status
- `GET /api/download/{job_id}` - Download transcription files
- `WebSocket /api/ws/progress/{job_id}` - Real-time progress updates

### Example API Usage

```python
import requests

# Submit transcription job
response = requests.post('/api/transcribe', json={
    'url': 'https://www.youtube.com/watch?v=VIDEO_ID',
    'mode': 'auto',
    'lang': 'en'
})

job_data = response.json()
job_id = job_data['job_id']

# Check status
status = requests.get(f'/api/job/{job_id}/status').json()

# Download when complete
if status['status'] == 'complete':
    transcript = requests.get(f'/api/download/{job_id}?format=txt')
```

## ğŸš€ Deployment

### Development
```bash
# Start with auto-reload
python main.py
```

### Production
```bash
# Start with uvicorn (recommended)
uvicorn main:app --host 0.0.0.0 --port 5000 --workers 4

# Or with gunicorn + uvicorn workers
gunicorn main:app --bind 0.0.0.0:5000 --worker-class uvicorn.workers.UvicornWorker --workers 4
```

### Docker
```bash
# Build image
docker build -t youtube-transcription .

# Run container
docker run -p 5000:5000 -e OPENAI_API_KEY=your-key youtube-transcription
```

## ğŸ” Troubleshooting

### Common Issues

**FFmpeg Not Found**
```bash
# Install FFmpeg
sudo apt install ffmpeg  # Ubuntu/Debian
brew install ffmpeg       # macOS
```

**YouTube Access Blocked**
- Try using "captions" mode only
- Some videos may have restricted access
- Consider using different videos for testing

**Whisper Transcription Fails**
- Ensure OPENAI_API_KEY is set
- Check API quota and billing
- Verify internet connection

## ğŸ“ˆ Performance Tips

- Use "captions" mode when available (faster, no API costs)
- Enable caching for repeated requests
- Consider running with multiple workers in production
- Monitor memory usage with large batch operations

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [OpenAI Whisper](https://openai.com/research/whisper) - Speech recognition AI
- [yt-dlp](https://github.com/yt-dlp/yt-dlp) - YouTube video processing
- [FastAPI](https://fastapi.tiangolo.com/) - Modern web framework
- [Bootstrap](https://getbootstrap.com/) - UI components

## ğŸ“ Support

- ğŸ“§ Email: [support@example.com](mailto:support@example.com)
- ğŸ› Issues: [GitHub Issues](https://github.com/your-repo/issues)
- ğŸ’¬ Discussions: [GitHub Discussions](https://github.com/your-repo/discussions)